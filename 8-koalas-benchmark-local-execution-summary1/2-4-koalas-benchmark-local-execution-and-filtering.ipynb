{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "027ec26e-1a85-41f0-af1a-a0db50ac925a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Benchmark: Koalas (PySpark) and Dask - Local execution\n",
    "\n",
    "The benchmark was performed against the 2009 - 2013 Yellow Taxi Trip Records (157 GB) from NYC Taxi and Limousine Commission (TLC) Trip Record Data. We identified common operations from our pandas workloads such as basic calculations of statistics, join, filtering and grouping on this dataset.\n",
    "\n",
    "The operations were measured with/without filter operations to consider real world workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns of the dataset:\n",
    "\n",
    "```Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
    "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
    "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
    "      dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "986e1b95-41da-4ff6-9c9d-5ce33b2f7512",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YourAppName\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2888a8eb-675d-415f-9f68-d12458d1ce0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.databricks.io.cache.enabled is false\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "print(\"spark.databricks.io.cache.enabled is %s\" % spark.conf.get(\"spark.databricks.io.cache.enabled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "807b2e2b-ccc2-4800-a2e2-4b3bfc133a47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting koalas\n",
      "  Downloading koalas-1.8.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-16.0.0-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dask[complete]\n",
      "  Using cached dask-2024.5.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting click>=8.1 (from dask[complete])\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle>=1.5.0 (from dask[complete])\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask[complete])\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from dask[complete]) (24.0)\n",
      "Collecting partd>=1.2.0 (from dask[complete])\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.3.1 (from dask[complete])\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting toolz>=0.10.0 (from dask[complete])\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from dask[complete]) (7.1.0)\n",
      "Collecting pyarrow-hotfix (from dask[complete])\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting lz4>=4.3.2 (from dask[complete])\n",
      "  Downloading lz4-4.3.3-cp39-cp39-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from click>=8.1->dask[complete]) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[complete]) (3.17.0)\n",
      "Collecting locket (from partd>=1.2.0->dask[complete])\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting bokeh>=2.4.2 (from dask[complete])\n",
      "  Using cached bokeh-3.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2>=2.10.3 (from dask[complete])\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dask-expr<1.2,>=1.1 (from dask[complete])\n",
      "  Using cached dask_expr-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting distributed==2024.5.0 (from dask[complete])\n",
      "  Using cached distributed-2024.5.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting msgpack>=1.0.0 (from distributed==2024.5.0->dask[complete])\n",
      "  Downloading msgpack-1.0.8-cp39-cp39-win_amd64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: psutil>=5.7.2 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from distributed==2024.5.0->dask[complete]) (5.9.8)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed==2024.5.0->dask[complete])\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tblib>=1.6.0 (from distributed==2024.5.0->dask[complete])\n",
      "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tornado>=6.0.4 in c:\\users\\tomas\\anaconda3\\envs\\projectcdle\\lib\\site-packages (from distributed==2024.5.0->dask[complete]) (6.4)\n",
      "Collecting urllib3>=1.24.3 (from distributed==2024.5.0->dask[complete])\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting zict>=3.0.0 (from distributed==2024.5.0->dask[complete])\n",
      "  Using cached zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting contourpy>=1.2 (from bokeh>=2.4.2->dask[complete])\n",
      "  Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting pillow>=7.1.0 (from bokeh>=2.4.2->dask[complete])\n",
      "  Downloading pillow-10.3.0-cp39-cp39-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh>=2.4.2->dask[complete])\n",
      "  Using cached xyzservices-2024.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.10.3->dask[complete])\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Downloading koalas-1.8.2-py3-none-any.whl (390 kB)\n",
      "   ---------------------------------------- 0.0/390.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 390.8/390.8 kB 8.3 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Downloading pandas-2.2.2-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.2/11.6 MB 47.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 53.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.7/11.6 MB 54.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 54.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading pyarrow-16.0.0-cp39-cp39-win_amd64.whl (25.9 MB)\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.9/25.9 MB 19.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.9/25.9 MB 19.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.0/25.9 MB 21.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.9/25.9 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 7.1/25.9 MB 30.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.6/25.9 MB 34.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.4/25.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.0/25.9 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.5/25.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.1/25.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.9/25.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.9/25.9 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.9/25.9 MB 50.4 MB/s eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Downloading lz4-4.3.3-cp39-cp39-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.8/99.8 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached dask-2024.5.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached distributed-2024.5.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached bokeh-3.4.1-py3-none-any.whl (7.0 MB)\n",
      "Using cached dask_expr-1.1.0-py3-none-any.whl (205 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Downloading contourpy-1.2.1-cp39-cp39-win_amd64.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 182.8/182.8 kB 10.8 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Downloading msgpack-1.0.8-cp39-cp39-win_amd64.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.1/75.1 kB ? eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 31.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 26.8 MB/s eta 0:00:00\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached xyzservices-2024.4.0-py3-none-any.whl (81 kB)\n",
      "Using cached zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, zict, xyzservices, urllib3, tzdata, toolz, tblib, pyyaml, pyarrow-hotfix, pillow, numpy, msgpack, MarkupSafe, lz4, locket, fsspec, cloudpickle, click, pyarrow, partd, pandas, jinja2, contourpy, koalas, dask, bokeh, distributed, dask-expr\n",
      "Successfully installed MarkupSafe-2.1.5 bokeh-3.4.1 click-8.1.7 cloudpickle-3.0.0 contourpy-1.2.1 dask-2024.5.0 dask-expr-1.1.0 distributed-2024.5.0 fsspec-2024.3.1 jinja2-3.1.4 koalas-1.8.2 locket-1.0.0 lz4-4.3.3 msgpack-1.0.8 numpy-1.26.4 pandas-2.2.2 partd-1.4.2 pillow-10.3.0 pyarrow-16.0.0 pyarrow-hotfix-0.6 pytz-2024.1 pyyaml-6.0.1 sortedcontainers-2.4.0 tblib-3.0.0 toolz-0.12.1 tzdata-2024.1 urllib3-2.2.1 xyzservices-2024.4.0 zict-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U koalas dask[complete] numpy pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "687ee8ee-b008-4402-83eb-2e875bcb97c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found pyspark version \"3.5.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 2.2.2\n",
      "numpy version: 1.23.0\n",
      "koalas version: 1.8.2\n",
      "dask version: 2024.5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "print('pandas version: %s' % pd.__version__)\n",
    "print('numpy version: %s' % np.__version__)\n",
    "print('koalas version: %s' % ks.__version__)\n",
    "import dask\n",
    "print('dask version: %s' % dask.__version__)\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]\n",
    "\n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd778f3f-9ff7-4690-8787-b9c96ecac5bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ec018df-6146-43c5-9930-b71550778501",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e55da95-b3b5-486a-b2c0-2a59b455c4c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "dask_data = dd.read_parquet('../../Data/yellow_tripdata_2013-06.parquet',index='VendorID')\n",
    "\n",
    "dask_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'Airport_fee'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your Parquet file\n",
    "file_path = '../../Data/yellow_tripdata_2023-02.parquet'\n",
    "\n",
    "# Read the first few rows of the Parquet file\n",
    "df_sample = pd.read_parquet(file_path, engine='pyarrow')\n",
    "\n",
    "# Print the column names\n",
    "print(df_sample.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 00:32:53</td>\n",
       "      <td>2023-02-01 00:34:34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:35:16</td>\n",
       "      <td>2023-02-01 00:35:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:35:16</td>\n",
       "      <td>2023-02-01 00:35:30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-01 00:29:33</td>\n",
       "      <td>2023-02-01 01:01:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>70.9</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-02-01 00:12:28</td>\n",
       "      <td>2023-02-01 00:25:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2023-02-01 00:32:53   2023-02-01 00:34:34              2.0   \n",
       "1         2  2023-02-01 00:35:16   2023-02-01 00:35:30              1.0   \n",
       "2         2  2023-02-01 00:35:16   2023-02-01 00:35:30              1.0   \n",
       "3         1  2023-02-01 00:29:33   2023-02-01 01:01:38              0.0   \n",
       "4         2  2023-02-01 00:12:28   2023-02-01 00:25:46              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.30         1.0                  N           142           163   \n",
       "1           0.00         1.0                  N            71            71   \n",
       "2           0.00         1.0                  N            71            71   \n",
       "3          18.80         1.0                  N           132            26   \n",
       "4           3.22         1.0                  N           161           145   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          4.4   3.50      0.5         0.0           0.0   \n",
       "1             4         -3.0  -1.00     -0.5         0.0           0.0   \n",
       "2             4          3.0   1.00      0.5         0.0           0.0   \n",
       "3             1         70.9   2.25      0.5         0.0           0.0   \n",
       "4             1         17.0   1.00      0.5         3.3           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0          9.40                   2.5         0.00  \n",
       "1                   -1.0         -5.50                   0.0         0.00  \n",
       "2                    1.0          5.50                   0.0         0.00  \n",
       "3                    1.0         74.65                   0.0         1.25  \n",
       "4                    1.0         25.30                   2.5         0.00  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3416e44-4347-4bdc-8119-bdac11d3d921",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5e966e7-2907-479a-b847-e78da9cf6839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return dd.read_parquet('../../Data/yellow_tripdata_2013-06.parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df.fare_amount.mean().compute()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std().compute()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.tip_amount).mean().compute()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return (df.fare_amount + df.tip_amount).compute()\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.tip_amount).mean().compute()\n",
    "\n",
    "def product_columns(df):\n",
    "    return (df.fare_amount * df.tip_amount).compute()\n",
    "  \n",
    "def value_counts(df):\n",
    "    return df.fare_amount.value_counts().compute()\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.mean().compute()\n",
    "  \n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.compute()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amount': ['mean', 'std'], \n",
    "        'tip_amount': ['mean', 'std']\n",
    "      }\n",
    "    ).compute()\n",
    "other = groupby_statistics(dask_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(dd.merge(df, other, left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    return dd.merge(df, other, left_index=True, right_index=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc52a51e-934f-4bca-8c75-33cb048ce6dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file took: 0.017640352249145508 seconds\n",
      "count took: 0.10663700103759766 seconds\n",
      "count index length took: 0.869950532913208 seconds\n",
      "mean took: 2.00138783454895 seconds\n",
      "standard deviation took: 1.8177976608276367 seconds\n",
      "mean of columns addition took: 2.728876829147339 seconds\n",
      "addition of columns took: 6.491725444793701 seconds\n",
      "mean of columns multiplication took: 2.517961263656616 seconds\n",
      "multiplication of columns took: 6.112968921661377 seconds\n",
      "value counts took: 2.2724311351776123 seconds\n",
      "groupby statistics took: 3.4179625511169434 seconds\n",
      "join count took: 1.939040184020996 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.939040184020996"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=dask_data, benchmarks=dask_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=dask_data, benchmarks=dask_benchmarks, name='count index length')\n",
    "benchmark(mean, df=dask_data, benchmarks=dask_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=dask_data, benchmarks=dask_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_data, benchmarks=dask_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_data, benchmarks=dask_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=dask_data, benchmarks=dask_benchmarks, name='value counts')\n",
    "# No column for this\n",
    "#benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "#benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=dask_data, benchmarks=dask_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, dask_data, benchmarks=dask_benchmarks, name='join count', other=other)\n",
    "#benchmark(join_data, dask_data, benchmarks=dask_benchmarks, name='join', other=other)  cant join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64a39b73-b9b6-4b1b-9444-91e68f0ff42b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "002f1180-9191-4e93-8471-c2250ac37aaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expr_filter = (dask_data.tip_amount >= 1) & (dask_data.tip_amount <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "  \n",
    "dask_filtered = filter_data(dask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da0279d-9c0c-4d87-93c5-8ac67ef1412a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 1.571927785873413 seconds\n",
      "filtered count index length took: 1.6500351428985596 seconds\n",
      "filtered mean took: 2.652149200439453 seconds\n",
      "filtered standard deviation took: 3.2502121925354004 seconds\n",
      "filtered mean of columns addition took: 2.445396661758423 seconds\n",
      "filtered addition of columns took: 4.6458117961883545 seconds\n",
      "filtered mean of columns multiplication took: 2.4689013957977295 seconds\n",
      "filtered multiplication of columns took: 4.786742210388184 seconds\n",
      "filtered value counts took: 2.9803638458251953 seconds\n",
      "filtered groupby statistics took: 3.429048538208008 seconds\n",
      "filtered join count took: 2.0234270095825195 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0234270095825195"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(count, dask_filtered, benchmarks=dask_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_filtered, benchmarks=dask_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_filtered, benchmarks=dask_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered multiplication of columns')\n",
    "#benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "#benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_filtered, benchmarks=dask_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_filtered, benchmarks=dask_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(dask_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, dask_filtered, benchmarks=dask_benchmarks, name='filtered join count', other=other)\n",
    "#benchmark(join_data, dask_filtered, benchmarks=dask_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9793cfc-c8e3-4884-8217-641d854dab66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2f28615-1768-47f9-9732-eec909ef2249",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ec5af7b-d6ca-463d-b8e3-3863ecb0e30c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea5a66b1-9e5d-40bc-99a6-07c925ccb564",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "[dtype('int32'), dtype('<M8[us]'), dtype('<M8[us]'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('O'), dtype('int32'), dtype('int32'), dtype('int64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m koalas_data \u001b[38;5;241m=\u001b[39m \u001b[43mks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../Data/yellow_tripdata_2023-02.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m koalas_benchmarks \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: [],  \u001b[38;5;66;03m# in seconds\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m      6\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\tomas\\Anaconda3\\envs\\Projectcdle\\lib\\site-packages\\databricks\\koalas\\namespace.py:773\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, columns, index_col, pandas_metadata, **options)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_col\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m]})\n\u001b[0;32m    763\u001b[0m     index_col, index_names \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    764\u001b[0m         default_session()\n\u001b[0;32m    765\u001b[0m         \u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinaryFile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m    771\u001b[0m     )\n\u001b[1;32m--> 773\u001b[0m kdf \u001b[38;5;241m=\u001b[39m \u001b[43mread_spark_io\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    776\u001b[0m     new_columns \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m kdf\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32mc:\\Users\\tomas\\Anaconda3\\envs\\Projectcdle\\lib\\site-packages\\databricks\\koalas\\namespace.py:680\u001b[0m, in \u001b[0;36mread_spark_io\u001b[1;34m(path, format, schema, index_col, **options)\u001b[0m\n\u001b[0;32m    676\u001b[0m sdf \u001b[38;5;241m=\u001b[39m default_session()\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mload(path\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, schema\u001b[38;5;241m=\u001b[39mschema, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    677\u001b[0m index_spark_columns, index_names \u001b[38;5;241m=\u001b[39m _get_index_map(sdf, index_col)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\n\u001b[1;32m--> 680\u001b[0m     \u001b[43mInternalFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_spark_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_spark_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_names\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tomas\\Anaconda3\\envs\\Projectcdle\\lib\\site-packages\\databricks\\koalas\\internal.py:604\u001b[0m, in \u001b[0;36mInternalFrame.__init__\u001b[1;34m(self, spark_frame, index_spark_columns, index_names, index_dtypes, column_labels, data_spark_columns, data_dtypes, column_label_names)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_spark_columns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_dtypes), (\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mlen\u001b[39m(data_spark_columns),\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mlen\u001b[39m(data_dtypes),\n\u001b[0;32m    595\u001b[0m )\n\u001b[0;32m    597\u001b[0m data_dtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    598\u001b[0m     spark_type_to_pandas_dtype(spark_frame\u001b[38;5;241m.\u001b[39mselect(scol)\u001b[38;5;241m.\u001b[39mschema[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdataType)\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dtype, scol \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_dtypes, data_spark_columns)\n\u001b[0;32m    602\u001b[0m ]\n\u001b[1;32m--> 604\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(dtype, DtypeDataTypes)\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m as_spark_type(dtype, raise_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data_dtypes\n\u001b[0;32m    608\u001b[0m ), data_dtypes\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dtypes \u001b[38;5;241m=\u001b[39m data_dtypes\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m# column_label_names\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: [dtype('int32'), dtype('<M8[us]'), dtype('<M8[us]'), dtype('int64'), dtype('float64'), dtype('int64'), dtype('O'), dtype('int32'), dtype('int32'), dtype('int64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')]"
     ]
    }
   ],
   "source": [
    "koalas_data = ks.read_parquet('../../Data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "koalas_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5ce502-7635-4e45-b9d3-3d177272f4b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f60b01a-ffd1-4dc4-8e52-b0823164a61d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return ks.read_parquet('../../Data/yellow_tripdata_2013-06.parquet')\n",
    "  \n",
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df.fare_amount.mean()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.tip_amount).mean()\n",
    "\n",
    "def sum_columns(df):\n",
    "    x = df.fare_amount + df.tip_amount\n",
    "    x.to_pandas()\n",
    "    return x\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.tip_amount).mean()\n",
    "\n",
    "def product_columns(df):\n",
    "    x = df.fare_amount * df.tip_amount\n",
    "    x.to_pandas()\n",
    "    return x\n",
    "\n",
    "def value_counts(df):\n",
    "    val_counts = df.fare_amount.value_counts()\n",
    "    val_counts.to_pandas()\n",
    "    return val_counts\n",
    "  \n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2)\n",
    "    ret.to_pandas()\n",
    "    return ret\n",
    "  \n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df.start_lon\n",
    "    phi_1 = df.start_lat\n",
    "    theta_2 = df.end_lon\n",
    "    phi_2 = df.end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2) \n",
    "    return ret.mean()\n",
    "  \n",
    "def groupby_statistics(df):\n",
    "    gb = df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amount': ['mean', 'std'], \n",
    "        'tip_amount': ['mean', 'std']\n",
    "      }\n",
    "    )\n",
    "    gb.to_pandas()\n",
    "    return gb\n",
    "  \n",
    "other = ks.DataFrame(groupby_statistics(koalas_data).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    ret = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    ret.to_pandas()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4742e72-d7ae-469a-b482-dd57527147c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=koalas_benchmarks, name='read file')\n",
    "benchmark(count, df=koalas_data, benchmarks=koalas_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=koalas_data, benchmarks=koalas_benchmarks, name='count index length')\n",
    "benchmark(mean, df=koalas_data, benchmarks=koalas_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=koalas_data, benchmarks=koalas_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=koalas_data, benchmarks=koalas_benchmarks, name='value counts')\n",
    "benchmark(complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=koalas_data, benchmarks=koalas_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, koalas_data, benchmarks=koalas_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, koalas_data, benchmarks=koalas_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90805c0a-9f75-48fe-b055-730c915f2e55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22ce5f8c-1aee-4b1f-b438-bf59e6b21643",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expr_filter = (koalas_data.tip_amt >= 1) & (koalas_data.tip_amt <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "koalas_filtered = filter_data(koalas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41c33ab8-a07d-4e42-9ec1-a61715b23ad7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark(count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = ks.DataFrame(groupby_statistics(koalas_filtered).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "benchmark(join_data, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join', other=other)\n",
    "benchmark(join_count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join count', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed748f08-4137-4436-895f-c14ff3b4aa42",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71c69329-f35e-4ccc-8b0e-727bc3f0766d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "koalas_res_temp = get_results(koalas_benchmarks).set_index('task')\n",
    "dask_res_temp = get_results(dask_benchmarks).set_index('task')\n",
    "df = pd.concat([koalas_res_temp.duration, dask_res_temp.duration], axis=1, keys=['koalas', 'dask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b80db2ae-0157-465b-9f2b-2d4499411b57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "filename = '/dbfs/FileStore/koalas-benchmark-no-parquet-cache/single_node_' + datetime.now().strftime(\"%H%M%S\")\n",
    "print(filename)\n",
    "\n",
    "df.to_parquet(filename)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2-4-koalas-benchmark-local-execution-and-filtering",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "CDLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
