{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d67c10-e767-47cd-9d8c-88a1ea7648d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YourAppName\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5bb1a30-c021-4a1d-870a-fad8e04e05b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.databricks.io.cache.enabled is false\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.databricks.io.cache.enabled\", \"false\")\n",
    "print(\"spark.databricks.io.cache.enabled is %s\" % spark.conf.get(\"spark.databricks.io.cache.enabled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ad45452-09a6-44db-993a-61d6d227e806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.9/site-packages (1.4.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numpy>=1.18.5 in /databricks/python3/lib/python3.9/site-packages (from pandas) (1.21.5)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "989bf8f7-910f-46b1-92eb-78e8fb76ecad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.4.2\nnumpy version: 1.21.5\npyarrow version: 7.0.0\npyspark version: 3.3.2.dev0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import databricks.koalas as ks\n",
    "# import dask.dataframe as dd\n",
    "# from dask.distributed import Client, LocalCluster\n",
    "\n",
    "print('pandas version: %s' % pd.__version__)\n",
    "\n",
    "print('numpy version: %s' % np.__version__)\n",
    "\n",
    "#print('koalas version: %s' % ks.__version__)\n",
    "\n",
    "# import dask\n",
    "# print('dask version: %s' % dask.__version__)\n",
    "\n",
    "import pyarrow\n",
    "print('pyarrow version: %s' % pyarrow.__version__)\n",
    "\n",
    "import pyspark\n",
    "print('pyspark version: %s' % pyspark.__version__)\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "    return benchmarks['duration'][-1]\n",
    "\n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1d16d56-63b2-4921-ae08-c735227da893",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1433832980640685>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/FileStore/tables/yellow_trip_5_months.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#pandas_data = pd.read_parquet(file_path, engine=\"pyarrow\")\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m pandas_data \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39moptions(header\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mload(file_path)\u001B[38;5;241m.\u001B[39mtoPandas()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:302\u001B[0m, in \u001B[0;36mDataFrameReader.load\u001B[0;34m(self, path, format, schema, **options)\u001B[0m\n",
       "\u001B[1;32m    300\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
       "\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, \u001B[38;5;28mstr\u001B[39m):\n",
       "\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [COLUMN_ALREADY_EXISTS] The column `airport_fee` already exists. Consider to choose another name or rename the existing column."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-1433832980640685>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/FileStore/tables/yellow_trip_5_months.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#pandas_data = pd.read_parquet(file_path, engine=\"pyarrow\")\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m pandas_data \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mread\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparquet\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39moptions(header\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mload(file_path)\u001B[38;5;241m.\u001B[39mtoPandas()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:302\u001B[0m, in \u001B[0;36mDataFrameReader.load\u001B[0;34m(self, path, format, schema, **options)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(path) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [COLUMN_ALREADY_EXISTS] The column `airport_fee` already exists. Consider to choose another name or rename the existing column.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [COLUMN_ALREADY_EXISTS] The column `airport_fee` already exists. Consider to choose another name or rename the existing column.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"/FileStore/tables/yellow_trip_5_months.parquet\"\n",
    "#pandas_data = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
    "pandas_data = spark.read.format('parquet').options(header='true').load(file_path).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf255c1-9046-46d7-9d0a-42dd51cd5505",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VendorID</th>\n      <th>tpep_pickup_datetime</th>\n      <th>tpep_dropoff_datetime</th>\n      <th>passenger_count</th>\n      <th>trip_distance</th>\n      <th>RatecodeID</th>\n      <th>store_and_fwd_flag</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>payment_type</th>\n      <th>fare_amount</th>\n      <th>extra</th>\n      <th>mta_tax</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>improvement_surcharge</th>\n      <th>total_amount</th>\n      <th>congestion_surcharge</th>\n      <th>airport_fee</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2023-01-01 00:32:10</td>\n      <td>2023-01-01 00:40:36</td>\n      <td>1.0</td>\n      <td>0.97</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>161</td>\n      <td>141</td>\n      <td>2</td>\n      <td>9.3</td>\n      <td>1.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>14.30</td>\n      <td>2.5</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2023-01-01 00:55:08</td>\n      <td>2023-01-01 01:01:27</td>\n      <td>1.0</td>\n      <td>1.10</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>43</td>\n      <td>237</td>\n      <td>1</td>\n      <td>7.9</td>\n      <td>1.00</td>\n      <td>0.5</td>\n      <td>4.00</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>16.90</td>\n      <td>2.5</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2023-01-01 00:25:04</td>\n      <td>2023-01-01 00:37:49</td>\n      <td>1.0</td>\n      <td>2.51</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>48</td>\n      <td>238</td>\n      <td>1</td>\n      <td>14.9</td>\n      <td>1.00</td>\n      <td>0.5</td>\n      <td>15.00</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>34.90</td>\n      <td>2.5</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2023-01-01 00:03:48</td>\n      <td>2023-01-01 00:13:25</td>\n      <td>0.0</td>\n      <td>1.90</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>138</td>\n      <td>7</td>\n      <td>1</td>\n      <td>12.1</td>\n      <td>7.25</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>20.85</td>\n      <td>0.0</td>\n      <td>1.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>2023-01-01 00:10:29</td>\n      <td>2023-01-01 00:21:19</td>\n      <td>1.0</td>\n      <td>1.43</td>\n      <td>1.0</td>\n      <td>N</td>\n      <td>107</td>\n      <td>79</td>\n      <td>1</td>\n      <td>11.4</td>\n      <td>1.00</td>\n      <td>0.5</td>\n      <td>3.28</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>19.68</td>\n      <td>2.5</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922462c6-75b9-403d-a5ad-1cc0aa55b189",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a610bed-4c5a-4e49-b684-5f223d08a6b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_file_parquet():\n",
    "    return pd.read_parquet(\"/FileStore/tables/yellow_tripdata_2023_01.parquet\")\n",
    "\n",
    "def count(df):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df['fare_amount'].mean()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df['fare_amount'].std()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df['fare_amount'] + df['tip_amount']).mean()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return (df['fare_amount'] + df['tip_amount'])\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df['fare_amount'] * df['tip_amount']).mean()\n",
    "\n",
    "def product_columns(df):\n",
    "    return (df['fare_amount'] * df['tip_amount'])\n",
    "\n",
    "def value_counts(df):\n",
    "    return df['fare_amount'].value_counts()\n",
    "\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['start_lon']\n",
    "    phi_1 = df['start_lat']\n",
    "    theta_2 = df['end_lon']\n",
    "    phi_2 = df['end_lat']\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2 +\n",
    "            np.cos(theta_1*np.pi/180) * np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.mean()\n",
    "\n",
    "def complicated_arithmetic_operation(df):\n",
    "    theta_1 = df['start_lon']\n",
    "    phi_1 = df['start_lat']\n",
    "    theta_2 = df['end_lon']\n",
    "    phi_2 = df['end_lat']\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2 +\n",
    "            np.cos(theta_1*np.pi/180) * np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    result = df.groupby('passenger_count').agg(\n",
    "        fare_amount_mean=('fare_amount', 'mean'),\n",
    "        fare_amount_std=('fare_amount', 'std'),\n",
    "        tip_amount_mean=('tip_amount', 'mean'),\n",
    "        tip_amount_std=('tip_amount', 'std')\n",
    "    )\n",
    "    return result\n",
    "\n",
    "other = groupby_statistics(pandas_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(pd.merge(df, other, left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    return pd.merge(df, other, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4936f2f5-88b4-4aad-818a-fb4f4e841eb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_a</th>\n",
       "      <th>f_a</th>\n",
       "      <th>t_i</th>\n",
       "      <th>t_i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>16.258301</td>\n",
       "      <td>16.109847</td>\n",
       "      <td>2.870892</td>\n",
       "      <td>3.319242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17.864871</td>\n",
       "      <td>17.208074</td>\n",
       "      <td>3.324993</td>\n",
       "      <td>3.748582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>20.187780</td>\n",
       "      <td>20.151504</td>\n",
       "      <td>3.589881</td>\n",
       "      <td>4.222252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>19.665432</td>\n",
       "      <td>20.457761</td>\n",
       "      <td>3.370632</td>\n",
       "      <td>4.091855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>20.900318</td>\n",
       "      <td>22.510652</td>\n",
       "      <td>3.281927</td>\n",
       "      <td>4.365429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>17.897049</td>\n",
       "      <td>15.882436</td>\n",
       "      <td>3.383753</td>\n",
       "      <td>3.623471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>18.010731</td>\n",
       "      <td>16.029976</td>\n",
       "      <td>3.355087</td>\n",
       "      <td>3.670653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>68.166667</td>\n",
       "      <td>11.788412</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>8.057379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>82.113077</td>\n",
       "      <td>2.666813</td>\n",
       "      <td>13.389231</td>\n",
       "      <td>6.765661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f_a</th>\n      <th>f_a</th>\n      <th>t_i</th>\n      <th>t_i</th>\n    </tr>\n    <tr>\n      <th>passenger_count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>16.258301</td>\n      <td>16.109847</td>\n      <td>2.870892</td>\n      <td>3.319242</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>17.864871</td>\n      <td>17.208074</td>\n      <td>3.324993</td>\n      <td>3.748582</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>20.187780</td>\n      <td>20.151504</td>\n      <td>3.589881</td>\n      <td>4.222252</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>19.665432</td>\n      <td>20.457761</td>\n      <td>3.370632</td>\n      <td>4.091855</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>20.900318</td>\n      <td>22.510652</td>\n      <td>3.281927</td>\n      <td>4.365429</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>17.897049</td>\n      <td>15.882436</td>\n      <td>3.383753</td>\n      <td>3.623471</td>\n    </tr>\n    <tr>\n      <th>6.0</th>\n      <td>18.010731</td>\n      <td>16.029976</td>\n      <td>3.355087</td>\n      <td>3.670653</td>\n    </tr>\n    <tr>\n      <th>7.0</th>\n      <td>68.166667</td>\n      <td>11.788412</td>\n      <td>9.470000</td>\n      <td>8.057379</td>\n    </tr>\n    <tr>\n      <th>8.0</th>\n      <td>82.113077</td>\n      <td>2.666813</td>\n      <td>13.389231</td>\n      <td>6.765661</td>\n    </tr>\n    <tr>\n      <th>9.0</th>\n      <td>90.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c57236b-f190-478e-8f08-ba4e9c14e4ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count took: 0.00014901161193847656 seconds\ncount index length took: 7.152557373046875e-06 seconds\nmean took: 0.015315055847167969 seconds\nstandard deviation took: 0.055608510971069336 seconds\nmean of columns addition took: 0.026159286499023438 seconds\naddition of columns took: 0.008296489715576172 seconds\nmean of columns multiplication took: 0.01734137535095215 seconds\nmultiplication of columns took: 0.008443117141723633 seconds\nvalue counts took: 0.08369731903076172 seconds\ngroupby statistics took: 0.22147178649902344 seconds\njoin count took: 0.7389745712280273 seconds\njoin took: 0.7035892009735107 seconds\nOut[7]: 0.7035892009735107"
     ]
    }
   ],
   "source": [
    "#benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=pandas_data, benchmarks=pandas_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=pandas_data, benchmarks=pandas_benchmarks, name='count index length')\n",
    "benchmark(mean, df=pandas_data, benchmarks=pandas_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=pandas_data, benchmarks=pandas_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=pandas_data, benchmarks=pandas_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=pandas_data, benchmarks=pandas_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=pandas_data, benchmarks=pandas_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=pandas_data, benchmarks=pandas_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=pandas_data, benchmarks=pandas_benchmarks, name='value counts')\n",
    "# No column for this\n",
    "# benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "# benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=pandas_data, benchmarks=pandas_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, pandas_data, benchmarks=pandas_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, pandas_data, benchmarks=pandas_benchmarks, name='join', other=other) # cant join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7113c00b-e32d-4c21-b185-00cb657a4d50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b05ae9-a8dd-40e9-a019-f230e5044dc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "expr_filter = (pandas_data.tip_amount >= 1) & (pandas_data.tip_amount <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "  \n",
    "pandas_filtered = filter_data(pandas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d8f07d1-4359-44df-846b-b6433e7508e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered count took: 1.239776611328125e-05 seconds\nfiltered count index length took: 4.291534423828125e-06 seconds\nfiltered mean took: 0.0063076019287109375 seconds\nfiltered standard deviation took: 0.03155779838562012 seconds\nfiltered mean of columns addition took: 0.013622522354125977 seconds\nfiltered addition of columns took: 0.0085906982421875 seconds\nfiltered mean of columns multiplication took: 0.016338825225830078 seconds\nfiltered multiplication of columns took: 0.008226871490478516 seconds\nfiltered value counts took: 0.07968497276306152 seconds\nfiltered groupby statistics took: 0.11608219146728516 seconds\nfiltered join count took: 0.7741854190826416 seconds\nfiltered join took: 0.5692503452301025 seconds\nOut[9]: 0.5692503452301025"
     ]
    }
   ],
   "source": [
    "benchmark(count, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, pandas_filtered, benchmarks=pandas_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=pandas_filtered, benchmarks=pandas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, pandas_filtered, benchmarks=pandas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=pandas_filtered, benchmarks=pandas_benchmarks, name='filtered multiplication of columns')\n",
    "#benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "#benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, pandas_filtered, benchmarks=pandas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(pandas_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, pandas_filtered, benchmarks=pandas_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5c0d1f-e34f-480e-be10-3c3cb7e33f99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count index length</th>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard deviation</th>\n",
       "      <td>0.055609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean of columns addition</th>\n",
       "      <td>0.026159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition of columns</th>\n",
       "      <td>0.008296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean of columns multiplication</th>\n",
       "      <td>0.017341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiplication of columns</th>\n",
       "      <td>0.008443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value counts</th>\n",
       "      <td>0.083697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groupby statistics</th>\n",
       "      <td>0.221472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join count</th>\n",
       "      <td>0.738975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>join</th>\n",
       "      <td>0.703589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered count</th>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered count index length</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean</th>\n",
       "      <td>0.006308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered standard deviation</th>\n",
       "      <td>0.031558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean of columns addition</th>\n",
       "      <td>0.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered addition of columns</th>\n",
       "      <td>0.008591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered mean of columns multiplication</th>\n",
       "      <td>0.016339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered multiplication of columns</th>\n",
       "      <td>0.008227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered value counts</th>\n",
       "      <td>0.079685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered groupby statistics</th>\n",
       "      <td>0.116082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered join count</th>\n",
       "      <td>0.774185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered join</th>\n",
       "      <td>0.569250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n    </tr>\n    <tr>\n      <th>task</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>0.000149</td>\n    </tr>\n    <tr>\n      <th>count index length</th>\n      <td>0.000007</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.015315</td>\n    </tr>\n    <tr>\n      <th>standard deviation</th>\n      <td>0.055609</td>\n    </tr>\n    <tr>\n      <th>mean of columns addition</th>\n      <td>0.026159</td>\n    </tr>\n    <tr>\n      <th>addition of columns</th>\n      <td>0.008296</td>\n    </tr>\n    <tr>\n      <th>mean of columns multiplication</th>\n      <td>0.017341</td>\n    </tr>\n    <tr>\n      <th>multiplication of columns</th>\n      <td>0.008443</td>\n    </tr>\n    <tr>\n      <th>value counts</th>\n      <td>0.083697</td>\n    </tr>\n    <tr>\n      <th>groupby statistics</th>\n      <td>0.221472</td>\n    </tr>\n    <tr>\n      <th>join count</th>\n      <td>0.738975</td>\n    </tr>\n    <tr>\n      <th>join</th>\n      <td>0.703589</td>\n    </tr>\n    <tr>\n      <th>filtered count</th>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>filtered count index length</th>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>filtered mean</th>\n      <td>0.006308</td>\n    </tr>\n    <tr>\n      <th>filtered standard deviation</th>\n      <td>0.031558</td>\n    </tr>\n    <tr>\n      <th>filtered mean of columns addition</th>\n      <td>0.013623</td>\n    </tr>\n    <tr>\n      <th>filtered addition of columns</th>\n      <td>0.008591</td>\n    </tr>\n    <tr>\n      <th>filtered mean of columns multiplication</th>\n      <td>0.016339</td>\n    </tr>\n    <tr>\n      <th>filtered multiplication of columns</th>\n      <td>0.008227</td>\n    </tr>\n    <tr>\n      <th>filtered value counts</th>\n      <td>0.079685</td>\n    </tr>\n    <tr>\n      <th>filtered groupby statistics</th>\n      <td>0.116082</td>\n    </tr>\n    <tr>\n      <th>filtered join count</th>\n      <td>0.774185</td>\n    </tr>\n    <tr>\n      <th>filtered join</th>\n      <td>0.569250</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_res_temp = get_results(pandas_benchmarks).set_index('task')\n",
    "pandas_res_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a627ab-138e-45ae-8d18-7c226c9d7a14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e39508-46d5-46d3-ba8d-c8b2f8e90a7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pandas",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
